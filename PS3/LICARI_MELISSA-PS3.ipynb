{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "Make sure the following libraries load correctly (hit Ctrl-Enter). Note that while you are loading several powerful libraries, including machine learning libraries, the goal of this problem set is to implement several algorithms from scratch. In particular, you should *not* be using any built-in libraries for nearest neighbors, distance metrics, or cross-validation -- your mission is to write those algorithms in Python! Part 1 will be relatively easy; Part 2 will take more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction to the assignment\n",
    "\n",
    "For this assignment, you will be using the [Boston Housing Prices Data Set](http://www.kellogg.northwestern.edu/faculty/weber/emp/_session_3/boston.htm).  Please read about the dataset carefully before continuing.  Use the following commands to load the dataset:\n",
    "\n",
    "*NOTE - This dataset is similar to the one you used in PS1; we are just using a different method to load it this time. The column names and their order will remain the same for this dataset as was in PS1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load Boston housing data set\n",
    "data = np.loadtxt('data.txt')\n",
    "target = np.loadtxt('target.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column names and turning data into a dataframe\n",
    "col = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    " 'B', 'LSTAT']\n",
    "df = pd.DataFrame(data, columns = col)\n",
    "df['MEDV'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Experimental Setup\n",
    "\n",
    "The goal of the next few sections is to design an experiment to predict the median home value for an instance in the data.\n",
    "Before beginning the \"real\" work, refamiliarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CRIM    ZN     INDUS  CHAS       NOX        RM   AGE       DIS  RAD  \\\n",
      "0  0.218960  18.0  2.629288   0.0  0.869420  6.875396  65.2  4.347275  1.0   \n",
      "1  0.141576   0.0  7.315612   0.0  0.549711  6.499894  78.9  5.315684  2.0   \n",
      "2  0.380457   0.0  7.340354   0.0  0.697928  7.263489  61.1  5.356935  2.0   \n",
      "3  0.313563   0.0  2.562407   0.0  0.599629  7.209732  45.8  6.103983  3.0   \n",
      "4  0.330105   0.0  2.497337   0.0  0.476077  7.184111  54.2  6.264372  3.0   \n",
      "\n",
      "     TAX    PTRATIO           B     LSTAT  MEDV  \n",
      "0  307.0  15.534711  397.462329  5.715647  24.0  \n",
      "1  255.0  17.914131  397.012611  9.338417  21.6  \n",
      "2  243.0  17.919989  396.628236  4.142473  34.7  \n",
      "3  226.0  18.979527  398.564784  3.239272  33.4  \n",
      "4  234.0  18.708888  399.487766  6.115159  36.2  \n",
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigating dataframe\n",
    "print(df.head())\n",
    "print(df.isnull().sum())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Begin by writing a function to compute the Root Mean Squared Error for a list of numbers\n",
    "\n",
    "You can find the sqrt function in the Numpy package. Furthermore the details of RMSE can be found on [Wikipedia](http://en.wikipedia.org/wiki/Root-mean-square_deviation). Do not use a built-in function  to compute RMSE, other than numpy functions like `sqrt` and if needed, `sum` or other relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "compute_rmse\n",
    "\n",
    "Given two arrays, one of actual values and one of predicted values,\n",
    "compute the Roote Mean Squared Error\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "predictions : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "yvalues : array\n",
    "    Array of numerical values corresponding to the actual values for each of the N observations\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Root Mean Squared Error of the prediction\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(compute_rmse((4,6,3),(2,1,4)))\n",
    "3.16\n",
    "\"\"\"\n",
    "\n",
    "def compute_rmse(predictions, yvalues):\n",
    "    # taking the difference between the 2 arrays\n",
    "    diffs = (np.array(yvalues)-np.array(predictions))\n",
    "    # squaring the differences\n",
    "    squares = np.square(diffs)\n",
    "    # summing the squares\n",
    "    s = np.sum(squares)\n",
    "    # dividing by the length\n",
    "    inside = s/len(diffs)\n",
    "    # taking the square root\n",
    "    rmse = math.sqrt(inside)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "# testing the compute_rmse function\n",
    "print(compute_rmse((4,6,3),(2,1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Divide your data into training and testing datasets\n",
    "\n",
    "Randomly select 75% of the data and put this in a training dataset (call this \"bdata_train\"), and place the remaining 25% in a testing dataset (call this \"bdata_test\"). Do not use built-in functions.\n",
    "\n",
    "To perform any randomized operation, only use functions in the *numpy library (np.random)*. Do not use other packages for random functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 506\n",
      "Number of training examples: 379\n",
      "Number of testing examples: 127\n"
     ]
    }
   ],
   "source": [
    "# leave the following line untouched, it will help ensure that your \"random\" split is the same \"random\" split used by the rest of the class\n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "# splits data into training and testing sets\n",
    "train_percent = .75\n",
    "train_number = int(train_percent*len(data))\n",
    "print('Total examples: %i' % len(data))\n",
    "print('Number of training examples: %i' % train_number)\n",
    "print('Number of testing examples: %i' % (len(data) - train_number))\n",
    "\n",
    "ids = np.arange(0, len(df), 1)\n",
    "ids = np.random.permutation(ids)\n",
    "df_shuffled = df.iloc[ids]\n",
    "bdata_train = df_shuffled[:train_number]\n",
    "bdata_test = df_shuffled[train_number:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use a very bad baseline for prediction, and compute RMSE\n",
    "\n",
    "Let's start by creating a very bad baseline model that predicts median home values as the averages of `MEDV` based on adjacency to Charles River. \n",
    "\n",
    "Specifically, create a model that predicts, for every observation X_i, the median home value as the average of the median home values of all houses in the **training set** that have the same adjacency value as the observation.\n",
    "\n",
    "For example - For an input observation where `CHAS==1`, the model should predict the `MEDV` as the mean of all `MEDV` values in the training set that also have `CHAS==1`.\n",
    "\n",
    "\n",
    "\n",
    "Once the model is built, do the following:\n",
    "\n",
    "1. Compute the RMSE of the training set.\n",
    "2. Now compute the RMSE of the test data set (but use the model you trained on the training set!).\n",
    "3. How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in red and the test instances in blue. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "5. Add code to your function to measure the running time of your algorithm. How long does it take to compute the predicted values for the test data?\n",
    "\n",
    "\n",
    "*NOTE - Be careful while dealing with floats and integers. Additionally, the `groupby` operation might come handy here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def model(dataset):\n",
    "    start_time = time.time() # 1.3.5\n",
    "    # sets prediction values\n",
    "    pred = bdata_train['MEDV'].groupby(bdata_train['CHAS']).mean()\n",
    "\n",
    "    # assigns predictions for each value of the dataset\n",
    "    predicted = []\n",
    "    for i in dataset['CHAS']:\n",
    "        if i == 0:\n",
    "            predicted.append(pred[0])\n",
    "        else:\n",
    "            predicted.append(pred[1])\n",
    "    t1 = time.time() - start_time # 1.3.5\n",
    "    print(\"Time taken: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.1 Compute the RMSE of the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "8.963434181280334\n"
     ]
    }
   ],
   "source": [
    "pred_train = model(bdata_train)\n",
    "print(compute_rmse(pred_train, bdata_train['MEDV']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.2 Now compute the RMSE of the test data set (but use the model you trained on the training set!).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "9.292691153610612\n"
     ]
    }
   ],
   "source": [
    "pred_test = model(bdata_test)\n",
    "print(compute_rmse(pred_test, bdata_test['MEDV']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.3\n",
    "How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?**\n",
    "\n",
    "The RMSE for the training set is 8.96, while the RMSE for the testing set is 9.29. It makes sense that the RMSE would be worse for the testing set since the RMSE for the training set was trained with the same data, while the testing set is new to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.4 Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in red and the test instances in blue. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(bdata_test['MEDV'].values, pred_test, c = 'blue', label= 'Test')\n",
    "ax.scatter(bdata_train['MEDV'].values, pred_train, c = 'red', label = 'Training')\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.legend(loc=\"best\")\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.5 Add code to your function to measure the running time of your algorithm. How long does it take to compute the predicted values for the test data?**\n",
    "\n",
    "Time taken: 0.01 seconds to compute the predicted values for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nearest Neighbors: Distance function\n",
    "Let's try and build a machine learning algorithm to beat the \"Average Value\" baseline that you computed above.  Soon you will implement the Nearest Neighbor algorithm, but first you need to create a distance metric to measure the distance (and similarity) between two instances.  Write a generic function to compute the L-Norm distance (called the [*p*-norm][1] distance on Wikipedia). Verify that your function works by computing the Euclidean distance between the points (2,7) and (5,11), and then compute the Manhattan distance between (4,4) and (12,10).\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "distance\n",
    "\n",
    "Given two instances and a value for L, return the L-Norm distance between them\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x1, x2 : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "L: int\n",
    "    Value of L to use in computing distances\n",
    "\n",
    "Returns\n",
    "-------\n",
    "dist : int\n",
    "    The L-norm distance between instances\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(distance((2,7),(5,11),2))\n",
    "5\n",
    "\n",
    "\"\"\"\n",
    "# distance function\n",
    "\n",
    "def distance(x1, x2, L):\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "    dist = (np.sum((np.absolute((np.array(x1) - np.array(x2))))**L, axis =-1))**(1/L)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# testing Euclidean distance\n",
    "print(distance((2,7),(5,11),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n"
     ]
    }
   ],
   "source": [
    "# testing Manhattan distance\n",
    "print(distance((4,4),(12,10),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Nearest Neighbor algorithm\n",
    "\n",
    "Your next task is to implement a basic nearest neighbor algorithm from scratch.  Your simple model will use three input features (`CRIM, RM and ZN`) and a single output (`MEDV`).  In other words, you are modelling the relationship between median home value and crime rates, house size and the proportion of residential land zoned for lots.\n",
    "\n",
    "Use your training data (bdata_train) to \"fit\" your model, although as you know, with Nearest Neighbors there is no real training, you just need to keep your training data in memory.  Write a function that predicts the median home value using the nearest neighbor algorithm we discussed in class.  Since this is a small dataset, you can simply compare your test instance to every instance in the training set, and return the `MEDV` value of the closest training instance.  Have your function take L as an input, where L is passed to the distance function. Use L=2 for all questions henceforth unless explicitly stated otherwise.\n",
    "\n",
    "Make sure to do the following - \n",
    "1. Fill in the function specification below\n",
    "2. Use your algorithm to predict the median home value of every instance in the test set. Report the RMSE (\"test RMSE\")\n",
    "3. Use your algorithm to predict the median home value of every instance in the training set and report the training RMSE.\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in red and the test instances in blue. \n",
    "5. Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set.\n",
    "6. How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1 Fill in the function specification below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "Nearest Neighbors\n",
    "\n",
    "Implementation of nearest neighbors algorithm.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x_train: array\n",
    "    Array of numerical feature values for training the model.\n",
    "y_train: array\n",
    "    Array of numerical output values for training the model.\n",
    "x_test: array\n",
    "    Array of numerical feature values for testing the model.\n",
    "y_test: array\n",
    "    Array of numerical output values for testing the model.\n",
    "L: int\n",
    "    Order of L-norm function used for calculating distance.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Value of the RMSE from data.\n",
    "\"\"\"\n",
    "\n",
    "# function predicts the median home value using the nearest neighbor algorithm\n",
    "def nneighbor(x_train, y_train, x_test, y_test, L):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pred = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        # finds the distance\n",
    "        dists = distance(np.array(x_test[i]), np.array(x_train), L)\n",
    "        # finds the smallest distance\n",
    "        closest_point = np.argmin(dists)\n",
    "        # appends closest point to the predictions array\n",
    "        pred.append(np.array(y_train)[closest_point])\n",
    "    # computes RMSE of the predictions and the test values\n",
    "    rmse = compute_rmse(pred, y_test)   \n",
    "    print(\"Time taken: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    return rmse, pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2 Use your algorithm to predict the median home value of every instance in the test set. Report the RMSE (\"test RMSE\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "7.11504450215995\n"
     ]
    }
   ],
   "source": [
    "# specifying the data to pass into the nneighbor function\n",
    "x_train = bdata_train[['CRIM','RM','ZN']].values\n",
    "y_train = bdata_train[['MEDV']]\n",
    "x_test = bdata_test[['CRIM','RM','ZN']].values\n",
    "y_test = bdata_test[['MEDV']]\n",
    "\n",
    "# using algorithm to predict median home value of every instance in the test set\n",
    "rmse_test, test_pred = nneighbor(x_train,y_train,x_test,y_test , 2)\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.3 Use your algorithm to predict the median home value of every instance in the training set and report the training RMSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.01 seconds\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "rmse_train, train_pred = nneighbor(x_train,y_train,x_train,y_train , 2)\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.4 Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value \n",
    "of each instance on the y-axis. Color the training instances in red and the test instances in blue.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the scatter plot\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(bdata_test[['MEDV']], test_pred, c = 'blue', label = 'Test')\n",
    "ax.scatter(bdata_train[['MEDV']], train_pred, c = 'red', label = 'Training')\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.legend(loc=\"best\")\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.5 Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set.**\n",
    "\n",
    "The time taken to predict the nearest neighbors for all the values in the test data set was calculated in 2.2.2 and is:\n",
    "\n",
    "Time taken: 0.01 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.6 How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.3?**\n",
    "\n",
    "NN Test RMSE: 7.11504450215995\n",
    "Time taken: 0.01 seconds\n",
    "\n",
    "Baseline Test RMSE: 9.292691153610612\n",
    "Time taken: 0.01 seconds\n",
    "\n",
    "The RMSE for the nearest neighbors algorithm is better than that of the baseline. The run times appear to be equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results and Normalization\n",
    "\n",
    "If you were being astute, you would have noticed that we never normalized our features -- a big no-no with Nearest Neighbor algorithms.  Write a generic normalization function that takes as input an array of values for a given feature, and returns the standardized array (subtract the mean and divide by the standard deviation).\n",
    "\n",
    "Re-run the Nearest Neighbor algorithm on the normalized dataset (still just using `CRIM, RM and ZN` as input), and compare the RMSE from this method with your previous RMSE evaluations. What do you observe?\n",
    "\n",
    "*NOTE*: To normalize properly, you should compute the mean and standard deviation on the training set, and use the same values to normalize both the training and the testing dataset.\n",
    "\n",
    "*NOTE 2*: In this case, the normalization may or may not reduce the RMSE; don't get confused if you find that to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "Normalize data\n",
    "\n",
    "Normalize all of the features in a data frame.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "raw_data: array\n",
    "    Array of numerical values to normalize.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "normalized_data : array\n",
    "    The array with normalized values for all features\n",
    "\"\"\"\n",
    "# normalization function - takes in data, standard deviation, and mean\n",
    "def normalize(raw_data,s,m):\n",
    "    raw_data = np.array(raw_data)\n",
    "    normalized_data = (raw_data - m)/s\n",
    "    return normalized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "7.455732878524116\n",
      "Time taken: 0.01 seconds\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# calculating standard deviation and mean\n",
    "s = np.std(np.array(bdata_train[['CRIM','RM','ZN']]), axis=0)\n",
    "m = np.mean(np.array(bdata_train[['CRIM','RM','ZN']]), axis=0)\n",
    "\n",
    "# normalizing data\n",
    "x_train = normalize(bdata_train[['CRIM','RM','ZN']], s,m)\n",
    "x_test = normalize(bdata_test[['CRIM','RM','ZN']], s,m)\n",
    "\n",
    "# rerunning nearest neighbors with normalized data on test set\n",
    "rmse_test, test_pred = nneighbor(x_train,bdata_train[['MEDV']],x_test,bdata_test[['MEDV']] , 2)\n",
    "print(rmse_test)\n",
    "\n",
    "# rerunning nearest neighbors with normalized data on training set\n",
    "rmse_train, train_pred = nneighbor(x_train,bdata_train[['MEDV']],x_train,bdata_train[['MEDV']] , 2)\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results without normalization:\n",
    "Time taken: 0.02 seconds\n",
    "0.0\n",
    "\n",
    "Training results with normalization:\n",
    "Time taken: 0.02 seconds\n",
    "0.0\n",
    "\n",
    "Test results without normalization:\n",
    "Time taken: 0.01 seconds\n",
    "7.11504450215995\n",
    "\n",
    "Test results with normalization:\n",
    "Time taken: 0.01 seconds\n",
    "7.455732878524116\n",
    "\n",
    "We can see that the training RMSE and the time taken does not change before and after normalizing the data. This makes sense because the nearest neighbor algorithm was trained with the training data and should not be calculating any difference in distance between the closest point, as there should be a corresponding point because the training set is the same.\n",
    "\n",
    "We can see that the test RMSE increased after normalization, reflecting the changes in distance after the data has been made proportional in our nearest neighbors algorithm. The time taken between for the test data between the normalized and non-normalized data is equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optimization\n",
    "\n",
    "A lot of the decisions we've made so far have been arbitrary.  Try to increase the performance of your nearest neighbor algorithm by adding features that you think might be relevant, and by using different values of L in the distance function.  Try a model that uses a different set of 2 features, then try at least one model that uses more than 4 features, then try using a different value of L.  If you're having fun, try a few different combinations of features and L! Use the test set to report the RMSE values.\n",
    "\n",
    "What combination of features and distance function provide the lowest RMSE on the test set?  Do your decisions affect the running time of the algorithm?\n",
    "\n",
    "*NOTE:* For this and all subsequent questions, you should use normalized features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PS1, we saw a saw the strongest correlations between MEDV, RM, and ZN. So I will first attempt a model with these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "9.346160102492217\n",
      "Time taken: 0.01 seconds\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "s1 = np.std(np.array(bdata_train[['RM','ZN']]), axis=0)\n",
    "m1 = np.mean(np.array(bdata_train[['RM','ZN']]), axis=0)\n",
    "\n",
    "x_train1 = normalize(bdata_train[['RM','ZN']], s1,m1)\n",
    "x_test1 = normalize(bdata_test[['RM','ZN']], s1,m1)\n",
    "\n",
    "rmse_test1, test_pred1 = nneighbor(x_train1,bdata_train[['MEDV']],x_test1,bdata_test[['MEDV']] , 2)\n",
    "print(rmse_test1)\n",
    "\n",
    "rmse_train1, train_pred1 = nneighbor(x_train1,bdata_train[['MEDV']],x_train1,bdata_train[['MEDV']] , 2)\n",
    "print(rmse_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to try features with the lowest correlation, so I will try LSTAT and INDUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "7.1875110407309935\n",
      "Time taken: 0.01 seconds\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "s2 = np.std(np.array(bdata_train[['LSTAT','INDUS']]), axis=0)\n",
    "m2 = np.mean(np.array(bdata_train[['LSTAT','INDUS']]), axis=0)\n",
    "\n",
    "x_train2 = normalize(bdata_train[['LSTAT','INDUS']], s2,m2)\n",
    "x_test2 = normalize(bdata_test[['LSTAT','INDUS']], s2,m2)\n",
    "\n",
    "rmse_test2, test_pred2 = nneighbor(x_train2,bdata_train[['MEDV']],x_test2,bdata_test[['MEDV']] , 2)\n",
    "print(rmse_test2)\n",
    "\n",
    "rmse_train2, train_pred2 = nneighbor(x_train2,bdata_train[['MEDV']],x_train2,bdata_train[['MEDV']] , 2)\n",
    "print(rmse_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try all 4 features above and include TAX with different distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "5.981658316927876\n",
      "Time taken: 0.01 seconds\n",
      "0.0\n",
      "Time taken: 0.01 seconds\n",
      "5.988006385470956\n",
      "Time taken: 0.00 seconds\n",
      "5.910187387945489\n"
     ]
    }
   ],
   "source": [
    "s3 = np.std(np.array(bdata_train[['LSTAT','INDUS','RM','ZN','TAX']]), axis=0)\n",
    "m3 = np.mean(np.array(bdata_train[['LSTAT','INDUS','RM','ZN','TAX']]), axis=0)\n",
    "\n",
    "x_train3 = normalize(bdata_train[['LSTAT','INDUS','RM','ZN','TAX']], s3,m3)\n",
    "x_test3 = normalize(bdata_test[['LSTAT','INDUS','RM','ZN','TAX']], s3,m3)\n",
    "\n",
    "# Euclidean distance\n",
    "rmse_test3, test_pred3 = nneighbor(x_train3,bdata_train[['MEDV']],x_test3,bdata_test[['MEDV']] , 2)\n",
    "print(rmse_test3)\n",
    "\n",
    "rmse_train3, train_pred3 = nneighbor(x_train3,bdata_train[['MEDV']],x_train3,bdata_train[['MEDV']] , 2)\n",
    "print(rmse_train3)\n",
    "\n",
    "# L=3\n",
    "rmse_test_m4, test_pred_m4 = nneighbor(x_train3,bdata_train[['MEDV']],x_test3,bdata_test[['MEDV']], 3)\n",
    "print(rmse_test_m4)\n",
    "\n",
    "# Manhattan Distance\n",
    "rmse_test_m5, test_pred_m5 = nneighbor(x_train3,bdata_train[['MEDV']],x_test3,bdata_test[['MEDV']], 1)\n",
    "print(rmse_test_m5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What combination of features and distance function provide the lowest RMSE on the test set? Do your decisions affect the running time of the algorithm?\n",
    "\n",
    "The combination of features that provided the lowest RMSE (5.910187387945489) on the test set was the features: LSTAT, INDUS, RM, ZN, and TAX with the manhattan distance (L=1). My decisions did not seem to affect the running time of the algorithm, at least not within one hundreth of a second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cross-Validation\n",
    "\n",
    "The more you tinkered with your features and distance function, the higher the risk that you overfit your training data.  One solution to this sort of overfitting is to use cross-validation (see K-fold [cross-validation][1].  Here you must implement a simple k-fold cross-validation algorithm yourself.  The function you write here will be used several more times in this problem set, so do your best to write efficient code! (Note that the sklearn package has a built-in [K-fold][2] iterator -- you should *not* be invoking that or any related algorithms in this section of the problem set.)\n",
    "\n",
    "Use 25-fold cross-validation and report the average RMSE for Nearest Neighbors using Euclidean distance with `CRIM,RM and ZN` input features, as well as the total running time for the full run of 25 folds.  In other words, randomly divide your training dataset (created in 1.2) into 25 equally-sized samples.\n",
    "\n",
    "For each of the 25 iterations (the \"folds\"), use 24 samples as \"training data\" (even though there is no training in k-NN!), and the remaining 1 sample for validation.  Compute the RMSE of that particular validation set, then move on to the next iteration.  \n",
    "\n",
    " - Report the average cross-validated RMSE across the 25 iterations. What do you observe?\n",
    " \n",
    " - Create a histogram of the RMSEs for the folds (there should be 25 of these). Additionally, use a horizontal line to mark the average cross-validated RMSE.\n",
    "\n",
    "\n",
    "[1]: http://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "[2]: http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "\n",
    "\n",
    "NOTE: To perform any randomized operation, only use functions in the *numpy library (np.random)*. Do not use other packages for random functions.\n",
    "\n",
    "HINT: Running 25-fold cross validation might be time-consuming. Try starting with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(data,k,model,K):\n",
    "    start_time_total = time.time()\n",
    "    \n",
    "    # splits the data into separate partitions\n",
    "    partitions = [int(x) for x in np.linspace(0, len(data), k+1)]\n",
    "    x_splits = [data[partitions[i]:partitions[i+1]][model] for i in range(len(partitions)-1)]\n",
    "    y_splits = [data[partitions[i]:partitions[i+1]][['MEDV']] for i in range(len(partitions)-1)]\n",
    "    \n",
    "    # caluculated the mean and standard deviation to be used for normalization across all splits\n",
    "    s = np.std(np.array(data[model]), axis=0)\n",
    "    m = np.mean(np.array(data[model]), axis=0)\n",
    "    \n",
    "    rmses = []\n",
    "    for i in range(k): # runs k folds\n",
    "        # defines data splits\n",
    "        x_train = np.concatenate(x_splits[:i] + x_splits[i+1:])\n",
    "        y_train = np.concatenate(y_splits[:i] + y_splits[i+1:])\n",
    "        x_val = np.array(x_splits[i])\n",
    "        y_val = np.array(y_splits[i])\n",
    "        \n",
    "        # normalizes data\n",
    "        x_train_norm = normalize(np.array(x_train),s,m)\n",
    "        x_val_norm = normalize(np.array(x_val),s,m)\n",
    "       \n",
    "        \n",
    "        if K == 0: # runs nearest neighbor function if K is 0\n",
    "            rmse_test, test_pred = nneighbor(x_train_norm,y_train,x_val_norm,y_val, 2)\n",
    "        else: # runs knn otherwise\n",
    "            rmse_test, test_pred = knn(x_train_norm, y_train, x_val_norm, y_val, 2, K)\n",
    "        rmses.append(rmse_test)\n",
    "        \n",
    "    print(\"Total time taken: {:.2f} seconds\".format(time.time() - start_time_total))\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# Report the average cross-validated RMSE across the 25 iterations. What do you observe?\n",
    "rmses = crossval(bdata_train,25,['CRIM','RM','ZN'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.800408907307364\n"
     ]
    }
   ],
   "source": [
    "# Report the average cross-validated RMSE across the 25 iterations. What do you observe?\n",
    "avg = np.mean(np.array(rmses))\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running nearest neighbors under cross validation seems to return a lower average RMSE (6.80) across the 25 iterations than running nearest neighbors alone on the test set. Could indicate that we might get a lower RMSE when we train with cross validation before running an algorithm on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a histogram of the RMSEs for the folds (there should be 25 of these). \n",
    "#Additionally, use a horizontal line to mark the average cross-validated RMSE.\n",
    "\n",
    "plt.hist(rmses, facecolor='thistle', edgecolor='white')\n",
    "plt.axvline(x=avg)\n",
    "\n",
    "plt.xlabel(\"RMSE Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"RMSE Across 25 folds\")\n",
    "\n",
    "#polishing\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 K-Nearest Neighbors Algorithm\n",
    "\n",
    "Implement the K-Nearest Neighbors algorithm.  Use 10-fold cross validation and L2 normalization, and the same features as in 2.5. Report the RMSE for K=5 and the running time of the algorithm. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "K-Nearest Neighbors\n",
    "\n",
    "Implementation of nearest neighbors algorithm.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x_train: array\n",
    "    Array of numerical feature values for training the model.\n",
    "y_train: array\n",
    "    Array of numerical output values for training the model.\n",
    "x_test: array\n",
    "    Array of numerical feature values for testing the model.\n",
    "y_test: array\n",
    "    Array of numerical output values for testing the model.\n",
    "L: int\n",
    "    Order of L-norm function used for calculating distance.\n",
    "K: int\n",
    "    Neighbors to include in algorithm\n",
    "    \n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Value of the RMSE from data.\n",
    "\"\"\"\n",
    "\n",
    "def knn(x_train, y_train, x_test, y_test, L, K):\n",
    "    start_time = time.time()\n",
    "    pred = []\n",
    "    for i in range(len(x_test)):\n",
    "        # finds the distances\n",
    "        dists = distance(np.array(x_test[i]), np.array(x_train), L)\n",
    "        # finds the average of the K nearest distances\n",
    "        avg = [np.array(y_train[np.argsort(dists)[:K]].mean())]\n",
    "        pred.append(avg) \n",
    "    # computes RMSE    \n",
    "    rmse = compute_rmse(np.array(pred), np.array(y_test))\n",
    "    print(\"Time taken: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    return rmse, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# Report the RMSE for K=5 and the running time of the algorithm. What do you observe?\n",
    "rmses = crossval(bdata_train,10,['CRIM','RM','ZN'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.23747187990516\n"
     ]
    }
   ],
   "source": [
    "# Report the RMSE for K=5 and the running time of the algorithm. What do you observe?\n",
    "avg = np.mean(np.array(rmses))\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average RMSE for KNN (5.23) is lower than the average RMSE for NN (6.80), which implies KNN will be a better algorithm for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Using cross validation to find K\n",
    "\n",
    "Compute the cross-validated RMSE for values of K between 1 and 25 using 10-fold cross-validation and L2 normalization.  Use the following features in your model: `CRIM, ZN, RM, AGE, DIS, TAX`.  Create a graph that shows how cross-validated RMSE changes as K increases from 1 to 25.  Label your axes, and summarize what you see.  What do you think is a reasonable choice of K for this model?\n",
    "\n",
    "Finally, report the test RMSE using the value of K that minimized the cross-validated RMSE. (Continue to use L2 normalization and the same set of features). How does the test RMSE compare to the cross-validated RMSE, and is this what you expected? How does the test RMSE compare to the test RMSE from 2.4, and is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.03 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.03 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.03 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Time taken: 0.00 seconds\n",
      "Total time taken: 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for i in range(1,26):\n",
    "    rmse = crossval(bdata_train,10,['CRIM','ZN','RM','AGE','DIS','TAX'],i)\n",
    "    rmses.append(np.mean(np.array(rmse)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdCklEQVR4nO3debxd873/8dc7g58gqJrHlBqKVtTUorcolSrltlXCRfxcP9qabqtU66JutVxD1Y9SVNNclFxDqdsGVaFmDamatRJjiJBIjJXkc//4fg8rO3vvs8/JWfucs877+Xicx1l7Td/PGvZnf9d3rf3digjMzKx6BvV2AGZmVg4neDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygu9jJI2QFJKG9HYsVSTpJEmX9mL5P5Q0Q9JLJa3/DUlrtzhvSPpog2ljJN3Rs9FZu1U6wUuaKuntfNK/JGmspKUK08fmk/xLNcudncePya8Xk3SmpOfzuqZI+kmDcjr+zm0S13qS/ju/0V+X9JCkb0kaXMJu6NMkTZT0jqQ1CuN2lDS1F8MqRd7GbwMbRsTKdaZvl8+782rG39FxLnYmIpaKiKd7JOBekPfB870dR1VUOsFnu0XEUsBIYFPguJrpTwIHdLzINec9gb8X5jkO2BzYEhgObA88WK+cwt9h9YKRtA5wL/Ac8PGIWCaXt3le90D0JvDvvR1EV3XjKmst4NWImN5knjeB/SWN6HZgfUxfuBodiJUnGBgJHoCIeAm4kZToi34LbCPpQ/n1KOAhoHgJvQVwbUS8GMnUiBjXzVB+ANwVEd+KiGk5ticiYp+ImFWYb19Jz+Za/vc7RkraUtLdkmZJmibpXEmLFaaHpEMlPSVppqTzJClPG5yvRGbkq5DDis1BkpaR9Iu83hdyc0LdN0azOJT8RNL0whXKxk32yTnA6CbNBQs0JeQrrx/m4e3yldUxubxpkvaQtIukJyW9Jul7NatcXNKVkuZIekDSJoV1ryrpakmv5H10RGHaSZKuknSppNnAmDqxLiNpXF7+GUnHSxokaUfgZmDVfIU3tsG+mAWMBU5stLMk/V9Jj+Xje6OktertK0kflvRbSbMl3Z+PZ22zy471zpUPVqf/n4/h45I+V7Ofrs/792+SDm62n/L58uccy8uSzmq0fTXbOlHSf0i6Mx+vmyQtX5i+raS78nn4nD646h4r6XxJv5P0JrB9J8e2W+ezpP8j6Qyl9+rLki6QNCxPW17SDXmdr0n6k6T25tyIqOwfMBXYMQ+vDvwV+Glh+ljgh8CFwNfzuPHAaOAOYEwedzzwLPAN4OOAGpXTQkwvAQc2mT4CCOAiYBiwCfAu8LE8fTPgU8CQPO9jwFGF5QO4AVgWWBN4BRiVpx0KPJr3xYeAP+T5h+TpvwF+DiwJrAjcBxzSIM6GcQA7A5NyDAI+BqzSYD0TgX8FzgIuzeN2BKbWbNNHa49bHt4OmAucAAwFDs7bfDnpimgj4B1g7Tz/ScB7wFfz/EcDU/LwoBz3CcBiwNrA08DONcvukecdVmd7xgHX5bJHkK4QDyrE+nyTY78d8DywMjAbWD+PL56LewB/y/t0COncvKvevgKuyH9LABuSrhrvaPFcGZP367/lfbMX8DqwXJ5+G/AzYHFSpekV4HON9hNwN7Bfnr4U8Klm+6Dm/Pg7sF5ez0Tg1DxtTWAO6f06FPgwMLJwjrwObJNjWKKTY9ut8xk4G7geWI50zH8L/DhP+zFwQY5tKPAZanJH6TmwnYW1+4+UeN/IJ0EAtwDL1iYKYNt8Ai4DvJxPpOKbajDwTeBOUrJ9ETigTjmzCn8HN4jpPfKbqMH0ETnW1Qvj7gP2bjD/UaSri+KbdtvC6/HAd/PwHykkbFIijXxSr5S3bVhh+mjg1hb39ftxADuQEtungEGdLDeRlOBXyG/Ijeh6gn8bGJxfD8/zb1WYfxKwRx4+CbinMG0QMC2/+bYCnq2J7zjgl4Vlb2+yLYPzPtywMO4QYGIh1k4TfB7+T+DKPFw8F39P/sAoxP8WsFZxX+VY3iN/SORpP2ThBN/oXBlDOs9VmH4fsB+wBjAPGF6Y9mNgbKP9BNxOunpdvpPzYYF9lM+P4wuvvwFMKBybaxusZywwrvC66bHtzvlMSvZvAusUxn0amJKHTyZ92H+0Xhnt+BsITTR7RMRw0omzAbB87QwRcQcpwRwP3BARb9dMnxcR50XENqRP8VOASyR9rKacZQt/FzWI51VglRbiLjYRvUWq9XTcoL1B6abxbOBHdbap7rLAqqRaXIfi8FqkWsa0fEk5i1SbX7FecM3iiIg/AucC5wEvS7pQ0tLNNjYiXsnLnNxsvgZejYh5ebjj2L1cmP42H+wDKGx3RMwn1ZpXJe2DVTu2P++D75E+/BZato7lSbXDZwrjngFWa31T3ncasHOx+ShbC/hpIb7XSImmtowVSB/cjY53h0bnCsALkTNV9gxpP60KvBYRc2qmFWOoLesgUi388dxctGudWBppFOMaLHivrFbt+d3w2HbzfF6BfGVQWOeEPB7gdNLV1k2Snpb03S5sc48YCAkegIi4jfSpfkaDWS4lPeHQtG09It6OiPOAmaTL3q76A/CVbizX4XzgcWDdiFiadJKq+SLvm0ZqnumwRmH4OVLtc/nCh9TSEbFRd+KIiHMiYjNSjXw94DstxHc66Qb2ZjXj3yK9kTos9ARKFxWf2BlE2icvkvbBlJoP6uERsUth2aCxGaRa81qFcWsCL3Q1wIh4lXT5/x81k54jXYUVYxwWEXfVzPcKqYml0fFuxWo1bfJrkvbTi8BykobXTCtu5wL7KSKeiojRpArDacBVkpbsYjy1ngPWaTK9GENnx7Y75/MMUuVho8I6l4n0UAcRMScivh0RawO7Ad8q3sdohwGT4LOzgZ0kjawz7RxgJ9Kl5AIkHaV0M2+YpCGSDiA1BTzYjRhOBLaWdLqklfP6P5pvSC3bwvLDSe2zb0jaAPh6F8oeDxwpabVc1rEdEyLd8L0JOFPS0ko3BteR9NmuxiFpC0lbSRpKuoR9h3RJ31Skm8xnAsfUTJoM7KN0k3gU0CimVm0m6ctKN5ePIn2w3UNqgpgt6dh8rAdL2ljSFq2sNF9FjAdOkTRc6ebnt0iVh+44C9ia1Obb4QLgOEkbwfs3dfdsEMs1wEmSlsjHaP8ulr8icISkobmMjwG/i4jngLuAH0taXNInSDX0yxqtSNK/SFohXzHNyqM7PSc6cRnpJvHX8vvyww3e29D5se3y+Zy35SLgJ5JWzPOuJmnnPLxrfm8rr3teD2xzlwyoBJ+bAcZR55G8iHgtIm6puSTt8DYp8bxE+tT+JvCVWPB5499qwefgr20Qw99J7XQjgEckvQ5cDfyZdK+gM0cD++R5LwKubGGZDheRkvhDpA+n35FqeR0n3f6kJoZHSVcoV9G4OalZHEvncTNJl+6v0vjKqdZPWfhNcCSpBjQL2Jd0M3hRXEe6aTiT1Kb85Yh4LyfF3Ug3DaeQjvXFpHszrTqclASeJrWdXw5c0p0gI2I2qS1+ucK4a0k14CtyU8LDwBcarOIwUuwvAf8F/Jr0Ydaqe4F1SfvhFOCr+coC0v2ZEaTa/LXAiRFxc5N1jSKd72+QjvHeEfFOF2JZSEQ8C+xCuvJ+jVQRqG3S6pi3s2Pb3fP5WFIzzD35ePwBWD9PWze/foN0j+9nETGx2xvcDaqfz2wgkPQF4IKIWKvTma3fk3QasHJEHNDbsVh7DKga/ECXL013yZezq5Gai+peaVj/J2kDSZ9QsiWpGcXHewBxgh9YRHpUbSapieYx0nPBVk3DSe3wb5LuDZxJap6yAcJNNGZmFeUavJlZRfV6J0BFo0aNigkTJvR2GGZm/UnD78H0qRr8jBkzejsEM7PK6FMJ3szMeo4TvJlZRZWa4CUtq9Qv9ONK/Vd/uszyzMzsA2XfZP0pqWvPryp1nr9EZwuYmVnPKC3B5+40/4n8qzcR8Q/gH2WVZ2ZmCyqziWZtUpelv5T0oKSLe6B7UDMza1GZCX4I8Eng/IjYlPR16bZ3eG9mNlCVmeCfJ/301r359VWkhG9mZm1QWoKPiJeA5yR19I38OVI/42Zm1gZlP0VzOHBZfoLmaeDAsgqaP28+gwZ3/nnV6nxmZv1dqQk+IiYDm5dZRodBgwfxxMQnOp1v/e3W73QeM7MqcFXWzKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyinODNzFo0f978Ls3X1fl7Wtn9wZuZ9Vld/R2JrnZL3tvdmDvBm9mA1dsJuGxuojGzymilqaOs5pC+yDV4M6uMVmrk/bU23h2uwZtZn9TbNyirYMDW4P0j3WbtVfYNTVvYgE3wPnnM2svvufZz1dTMusVNKH3fgK3Bm9kHutNk6Rp53+cEb1ZBbu82cII36xWtJODiPE7Y1h1O8GY1uppMy2reKCZfJ2zrjlITvKSpwBxgHjA3IjYvszyzeqre34hZI+2owW8fETPaUI71Ae2o/Xa1ecMJ2AYqN9FYU32x9uuvo5u1puwEH8BNkgL4eURcWHJ5pRmo33x17des/yo7wW8TES9KWhG4WdLjEXF7yWWWoi8munY0h5hZ/1Vqgo+IF/P/6ZKuBbYE+mWCb4e+2BxiZv1XaQle0pLAoIiYk4c/D5xcVnl9kW8GmllvKrMGvxJwraSOci6PiAklltfn+GagmfWm0hJ8RDwNbFLW+s3MrDnfSTMzqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOziio9wUsaLOlBSTeUXZaZmX2gHTX4I4HH2lCOmZkVlJrgJa0OfBG4uMxyzMxsYWXX4M8GjgHml1yOmZnVKC3BS9oVmB4Rk8oqw8zMGiuzBr8N8CVJU4ErgB0kXVpieWZmVlBago+I4yJi9YgYAewN/DEi/qWs8szMbEEtJXhJwyStX3YwZmbWczpN8JJ2AyYDE/LrkZKu70ohETExInbtVoRmZtYtrdTgTwK2BGYBRMRkYERZAZmZWc9oJcHPjYjXS4/EzMx61JAW5nlY0j7AYEnrAkcAd5UblpmZLapWavCHAxsB7wK/BmYDR5UYk5mZ9YBOa/AR8Rbw/fxnZmb9RKcJXtKtQNSOj4gdSonIzMx6RCtt8EcXhhcHvgLMLSccMzPrKa000dT2JXOnpNtKisfMzHpIK000yxVeDgI2A1YuLSIzM+sRrTTRTCK1wYvUNDMFOKjMoMzMbNG10kTzkXYEYmZmPathgpf05WYLRsQ1PR+OmZn1lGY1+N2aTAvACd7MrA9rmOAj4sB2BmJmZj2rlZusSPoiqbuCxTvGRcTJZQVlZmaLrpX+4C8A9iL1SSNgT2CtkuMyM7NF1EpnY1tHxP7AzIj4AfBpYI1ywzIzs0XVSoJ/O/9/S9KqwHuAH500M+vjWmmDv0HSssDpwAOkJ2guKjMoMzNbdM2eg/8f4HLgrIh4E7ha0g3A4v6FJzOzvq9ZE82FwK7AFElXStoDCCd3M7P+oWGCj4jrImI06YmZa4ADgGclXSJpp3YFaGZm3dPpTdaIeDsiroyIfwY+D2wKTCg9MjMzWyStPAe/kqTDJd0J/Aa4idRlsJmZ9WHNbrIeDIwG1ic10RwTEXe2KzAzM1s0zR6T3Bo4FfhDRMxvUzxmZtZD3NmYmVlFtfJN1m6RtLik+yT9RdIjkn5QVllmZrawlnqT7KZ3gR0i4g1JQ4E7JP0+Iu4psUwzM8sa1uAl7VAY/kjNtKa/9gTpG1ER8UZ+OTT/RTfjNDOzLmrWRHNGYfjqmmnHt7JySYMlTQamAzdHxL1dC8/MzLqrWYJXg+F6r+uKiHkRMRJYHdhS0sZdC8/MzLqrWYKPBsP1XjcVEbOAicCorixnZmbd1+wm69qSrifV1juGya877Q9e0grAexExS9IwYEfgtEUN2MzMWtMswe9eGD6jZlrt63pWAX4laTDpSmF8RNzQxfjMzKybmn3R6bbi6/yo48bACxExvbMVR8RDpI7JzMysFzR7TPICSRvl4WWAvwDjgAcljW5TfGZm1k3NbrJ+JiIeycMHAk9GxMdJPUkeU3pkZma2SJol+H8UhncidRVMRLxUZkBmZtYzmiX4WZJ2lbQpsA35Rz4kDQGGtSM4MzPrvmZP0RwCnAOsDBxVqLl/DvifsgMzM7NF0+wpmiep88WkiLgRuLHMoMzMbNE1+0Wnc5otGBFH9Hw4ZmbWU5o10RwKPAyMB16kxf5nzMysb2iW4FcB9gT2AuYCVwJXR8TMdgRmZmaLpuFTNBHxakRcEBHbA2OAZYFHJO3XptjMzGwRdPqLTpI+CYwmPQv/e2BS2UGZmdmia3aT9QfArsBjwBXAcRExt12BmZnZomlWg/934Glgk/z3I0mQbrZGRHyi/PDMzKy7miX4Tvt8NzOzvqvZF52eqTc+9+++N1B3upmZ9Q3NugteWtJxks6V9Hklh5Oabb7WvhDNzKw7mjXR/BcwE7gb+FfgO8BiwO4RMbn80MzMbFE0/U3W3P87ki4GZgBrRsSctkRmZmaLpFl3we91DETEPGCKk7uZWf/RrAa/iaTZeVjAsPy64zHJpUuPzszMuq3ZUzSD2xmImZn1rGZNNGZm1o85wZuZVZQTvJlZRTnBm5lVlBO8mVlFlZbgJa0h6VZJj0l6RNKRZZVlZmYL6/QHPxbBXODbEfGApOHAJEk3R8SjJZZpZmZZaTX4iJgWEQ/k4TmkHw5ZrazyzMxsQW1pg5c0AtgUuLcd5ZmZWRsSvKSlgKuBoyJidmfzm5lZzyg1wUsaSkrul0XENWWWZWZmCyrzKRoBvwAei4izyirHzMzqK7MGvw2wH7CDpMn5b5cSyzMzs4LSHpOMiDtIXQubmVkv8DdZzcwqygnezKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyinODNzCrKCd7MrKKc4M3MKsoJ3sysopzgzcwqygnezKyiSkvwki6RNF3Sw2WVYWZmjZVZgx8LjCpx/WZm1kRpCT4ibgdeK2v9ZmbWnNvgzcwqygnezKyinODNzCrKCd7MrKLKfEzy18DdwPqSnpd0UFllmZnZwoaUteKIGF3Wus3MrHNuojEzqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOzinKCNzOrKCd4M7OKcoI3M6soJ3gzs4pygjczqygneDOziio1wUsaJekJSX+T9N0yyzIzswWVluAlDQbOA74AbAiMlrRhWeWZmdmCyqzBbwn8LSKejoh/AFcAu5dYnpmZFQwpcd2rAc8VXj8PbNVsgUmTJs2Q9EyJMZmZVc2EiBhVb0KZCV51xkWzBSJihZJiMTMbcMpsonkeWKPwenXgxRLLMzOzgjIT/P3AupI+ImkxYG/g+hLLMzOzgtKaaCJirqTDgBuBwcAlEfFIWeWZmdmCFNG0WdzMzPopf5PVzKyinODNzCqqXyT4gdjlgaSpkv4qabKkP/d2PGWRdImk6ZIeLoxbTtLNkp7K/z/UmzH2tAbbfJKkF/Lxnixpl96MsadJWkPSrZIek/SIpCPz+Kof60bb3Zbj3efb4HOXB08CO5EevbwfGB0Rj/ZqYCWTNBXYPCJm9HYsZZL0T8AbwLiI2DiP+0/gtYg4NX+gfygiju3NOHtSg20+CXgjIs7ozdjKImkVYJWIeEDScGASsAcwhmof60bb/TXacLz7Qw3eXR5UWETcDrxWM3p34Fd5+FekN0RlNNjmSouIaRHxQB6eAzxG+rZ71Y91o+1ui/6Q4Ot1edC2HdSLArhJ0iRJ/6+3g2mzlSJiGqQ3CLBiL8fTLodJeig34VSqqaJI0ghgU+BeBtCxrtluaMPx7g8JvstdHlTENhHxSVJvnN/Ml/VWXecD6wAjgWnAmb0aTUkkLQVcDRwVEbN7O552qbPdbTne/SHBD8guDyLixfx/OnAtqalqoHg5t112tGFO7+V4ShcRL0fEvIiYD1xEBY+3pKGkJHdZRFyTR1f+WNfb7nYd7/6Q4AdclweSlsw3ZJC0JPB54OHmS1XK9cABefgA4LpejKUtOpJc9s9U7HhLEvAL4LGIOKswqdLHutF2t+t49/mnaADyI0Rn80GXB6f0bkTlkrQ2qdYOqTuJy6u6zZJ+DWwHLA+8DJwI/AYYD6wJPAvsGRGVuSnZYJu3I12uBzAVOKSjbboKJG0L/An4KzA/j/4eqT26yse60XaPpg3Hu18keDMz67r+0ERjZmbd4ARvZlZRTvBmZhXlBG9mVlFO8GZmFeUEb6WQFJLOLLw+Oneo1RPrHivpqz2xrk7K2TP3AnhrzfgRefsOL4w7V9KYTtZ3qKT9O5lnjKRzG0x7owvhmznBW2neBb4safneDqQo907aqoOAb0TE9nWmTQeOzF++a0lEXBAR47pQfo+RVNrPc1rf5QRvZZkLXAj8W+2E2hp4R81U0naSbpM0XtKTkk6VtK+k+3Lf+OsUVrOjpD/l+XbNyw+WdLqk+3MnTocU1nurpMtJXzipjWd0Xv/Dkk7L404AtgUukHR6ne17BbiFD76FWVzfOpIm5I7i/iRpgzz+JElH5+Etcox355iL32RcNS//VO46ubjuMyU9IOkWSSvkcSMl3ZPXd21Hx1WSJkr6kaTbSB9Ge+Zt/Iuk2+tsk1WME7yV6TxgX0nLdGGZTYAjgY8D+wHrRcSWwMXA4YX5RgCfBb5ISsKLk2rcr0fEFsAWwMGSPpLn3xL4fkRsWCxM0qrAacAOpG8WbiFpj4g4GfgzsG9EfKdBrKcC365zVXAhcHhEbAYcDfyszrK/BA6NiE8D82qmjQT2yvtgL0kdfTEtCTyQO6G7jfQNWIBxwLER8QnSB9iJhXUtGxGfjYgzgROAnSNiE+BLDbbJKsQJ3kqTe80bBxzRhcXuz31ovwv8Hbgpj/8rKal3GB8R8yPiKeBpYANSnz37S5pM+gr8h4F18/z3RcSUOuVtAUyMiFciYi5wGdBSz515ffcB+3SMy70Gbg38d47j50Cx3xEkLQsMj4i78qjLa1Z9S0S8HhHvAI8Ca+Xx84Er8/ClwLb5w3PZiLgtj/9VTfxXFobvBMZKOpjU7YdVnNvlrGxnAw+Qaqwd5pIrF7kzpmI79ruF4fmF1/NZ8Hyt7WMjSF1LHx4RNxYnSNoOeLNBfPW6o+6KHwFXAR1NHoOAWRExsskynZVZ3AfzaPw+baWfkfe3OyIOlbQV6apnsqSREfFqC+uwfso1eCtV7jhqPKn5pMNUYLM8vDswtBur3lPSoNwuvzbwBHAj8PXcPSuS1su9cTZzL/BZScvnppbRpOaPlkTE46Ra9q759WxgiqQ9cwyStEnNMjOBOZI+lUft3WJxg4COexf7AHdExOvATEmfyeP3axS/pHUi4t6IOAGYwYLdcFsFuQZv7XAmcFjh9UXAdZLuI92obFS7buYJUiJbidSW/Y6ki0nNOA/kK4NX6OQn4CJimqTjgFtJNevfRURXu6w9BXiw8Hpf4HxJx5M+vK4A/lKzzEHARZLeBCYCr7dQzpvARpIm5fn3yuMPIN2HWILUXHVgg+VPl7QuaTtvqROTVYx7kzTrBZKWioiOp4e+S/ph5iN7OSyrGNfgzXrHF/OVwxDgGWBM74ZjVeQavJlZRfkmq5lZRTnBm5lVlBO8mVlFOcGbmVWUE7yZWUX9LwYu1/aTjq6cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.924371375718152\n",
      "Best choice of K: 4\n"
     ]
    }
   ],
   "source": [
    "# Create a graph that shows how cross-validated RMSE changes as K increases from 1 to 25. \n",
    "# Label your axes, and summarize what you see. What do you think is a reasonable choice of K for this model?\n",
    "y = np.arange(1, 26, 1)\n",
    "plt.figure()\n",
    "plt.bar(y, rmses, facecolor='thistle', edgecolor='white')\n",
    "\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"RMSE Value\")\n",
    "plt.title(\"RMSE Change as Number of Neighbors Increases\")\n",
    "\n",
    "#polishing\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(min(rmses))\n",
    "print(\"Best choice of K: \" + str(rmses.index(min(rmses))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the minimum RMSE value occurs at K = 4, which is verified by taking the index of the minimum value of our rmses array returned by our cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.01 seconds\n",
      "6.001738183265948\n"
     ]
    }
   ],
   "source": [
    "# report the test RMSE using the value of K that minimized the cross-validated RMSE\n",
    "s = np.std(np.array(bdata_train[['CRIM','ZN','RM','AGE','DIS','TAX']]), axis=0)\n",
    "m = np.mean(np.array(bdata_train[['CRIM','ZN','RM','AGE','DIS','TAX']]), axis=0)\n",
    "\n",
    "x_train = normalize(bdata_train[['CRIM','ZN','RM','AGE','DIS','TAX']], s,m)\n",
    "x_test = normalize(bdata_test[['CRIM','ZN','RM','AGE','DIS','TAX']], s,m)\n",
    "\n",
    "rmse, pred = knn(np.array(x_train), np.array(bdata_train[['MEDV']]), np.array(x_test), np.array(bdata_test[['MEDV']]), 2, 4)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the test RMSE compare to the cross-validated RMSE, and is this what you expected? How does the test RMSE compare to the test RMSE from 2.4, and is this what you expected?\n",
    "\n",
    "Our test RMSE (6.00) is higher than our cross-validated RMSE (4.92) and . This is to be expected, as we are using more data to find the neighbors and we are using every value in our training set to validate, thus we have a lower RMSE in cross validation.\n",
    "\n",
    "Our test RMSE (6.00) is also higher than our best RMSE from  2.4 (5.91). This could be because the features chosen LSTAT, INDUS, RM, ZN, and TAX perform better than the features selected here: CRIM, ZN, RM, AGE, DIS, TAX. We also used a different distance measure in 2.4 (Manhattan difference) where we used the Euclidean difference here. This could also potentially indicate that nearest neighbors performs better than KNN for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Credit: Forward selection\n",
    "\n",
    "Thus far the choice of predictor variables has been rather arbitrary. For extra credit, implement a basic [forward selection](https://see.stanford.edu/materials/aimlcs229/cs229-notes5.pdf) algorithm to progressively include features that decrease the cross-validated RMSE of the model. Note that the optimal value of K may be different for each model, so you may want to use cross-validation to choose K each time (but it is also fine if you fix K at the optimal value from 2.7).  Create a graph that shows RMSE as a function of the number of features in the model. Label each point on the x-axis with the name of the feature that is added at that step in the forward selection algorithm. *(For instance, if the optimal single-feature model has CRIM with RMSE = 10, and the optimal two-feature model has CRIM+ZN with RMSE=9, the first x-axis label will say CRIM and the second x-axis lable with say ZN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
